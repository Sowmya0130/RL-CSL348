{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80211bf",
   "metadata": {},
   "source": [
    "# RL PROJECT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab8fb6",
   "metadata": {},
   "source": [
    "### STUDENT NAME & ROLL NO :\n",
    "- Keerti (21CSU260)\n",
    "- Aditya Sindhu(21CSU278) \n",
    "- Sowmya Sri(21CSU326)\n",
    "- Snigdha (21CSU283)\n",
    "- Abhishek Dubey(21CSU323) \n",
    "\n",
    "\n",
    "Semester: 5th \n",
    "Group: AIML-B (A3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4556c4d",
   "metadata": {},
   "source": [
    "## PROBLEM STATEMENT \n",
    "\n",
    "Design an RL-based system for personalized dietary planning and exercise recommendations .\" The objective is to develop an RL agent that tailors dietary plans and exercise routines for individuals with diabetes, taking into account their specific health data, dietary preferences, and historical records, to optimize glycaemic control and overall health.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "dataset = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd741a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        # Initialize the state\n",
    "        self.state = self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        if self is None:\n",
    "            return None\n",
    "\n",
    "        # Randomly select an individual from the dataset\n",
    "        individual = random.choice(self.dataset)\n",
    "\n",
    "        # Initialize the state\n",
    "        state = individual[['blood_glucose_level', 'dietary_intake', 'physical_activity_level']]\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take the action\n",
    "        diet, exercise = action\n",
    "\n",
    "        # Update the state\n",
    "        next_state = self.update_state(diet, exercise)\n",
    "\n",
    "        # Calculate the reward\n",
    "        reward = self.calculate_reward(next_state)\n",
    "\n",
    "        return next_state, reward, False\n",
    "\n",
    "    def update_state(self, diet, exercise):\n",
    "        # Update the individual's blood glucose level, dietary intake, and physical activity level based on the diet and exercise choices\n",
    "        next_state = self.state.copy()\n",
    "\n",
    "        # Update the blood glucose level\n",
    "        next_state[0] += (diet == 'low_carb') - (diet == 'high_carb')\n",
    "\n",
    "        # Update the dietary intake\n",
    "        next_state[1] += (exercise == 'active') - (exercise == 'sedentary')\n",
    "\n",
    "        # Update the physical activity level\n",
    "        next_state[2] += (diet == 'low_carb') - (diet == 'high_carb')\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def calculate_reward(self, next_state):\n",
    "        # Calculate the reward based on the next state\n",
    "        reward = - (next_state[0] - 5.5)**2\n",
    "\n",
    "        return reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b54d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent:\n",
    "    def __init__(self, state_space, action_space, reward_function):\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.reward_function = reward_function\n",
    "\n",
    "        # Initialize the Q-table\n",
    "        self.Q_table = np.zeros((state_space.shape[0], action_space.shape[0]))\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state.\n",
    "\n",
    "        Args:\n",
    "            state: A vector of features representing the current state.\n",
    "\n",
    "        Returns:\n",
    "            An action from the action space.\n",
    "        \"\"\"\n",
    "\n",
    "        # Epsilon-greedy exploration\n",
    "        epsilon = 0.1\n",
    "        if random.random() < epsilon:\n",
    "            action = random.choice(self.action_space)\n",
    "        else:\n",
    "            action = np.argmax(self.Q_table[state])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Updates the Q-table based on the current experience.\n",
    "\n",
    "        Args:\n",
    "            state: A vector of features representing the current state.\n",
    "            action: The action that was taken.\n",
    "            reward: The reward that was received.\n",
    "            next_state: A vector of features representing the next state.\n",
    "        \"\"\"\n",
    "\n",
    "        alpha = 0.1\n",
    "        gamma = 0.9\n",
    "\n",
    "        # Update the Q-table\n",
    "        self.Q_table[state, action] += alpha * (reward + gamma * np.max(self.Q_table[next_state]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4fe067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent, environment, n_episodes):\n",
    "    for episode in range(n_episodes):\n",
    "        state = environment.reset()\n",
    "\n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "\n",
    "            next_state, reward, done = environment.step(action)\n",
    "\n",
    "            agent.learn(state, action, reward, next_state)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d916b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_agent(agent):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "    # Initialize the environment\n",
    "    environment = Environment(dataset)\n",
    "\n",
    "    # Get the individual's state\n",
    "    state = environment.reset()\n",
    "\n",
    "    # Generate the personalized dietary plan and exercise recommendations\n",
    "    diet, exercise = agent.act(state)\n",
    "\n",
    "    # Print the personalized dietary plan and exercise recommendations\n",
    "    print('Dietary plan:', diet)\n",
    "    print('Exercise recommendations:', exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diet_and_exercise(glucose_level, bmi):\n",
    "    # Function to map health states to dietary plans and exercise recommendations based on the dataset\n",
    "\n",
    "    # Define thresholds or ranges for health metrics based on the dataset characteristics\n",
    "    glucose_threshold = 140  # threshold for high blood glucose\n",
    "    bmi_threshold = 30  # threshold for high BMI\n",
    "\n",
    "    # Determine the health state based on thresholds or ranges and provide recommendations\n",
    "    if glucose_level > glucose_threshold and bmi > bmi_threshold:\n",
    "        # Scenario 1: Elevated blood glucose and higher BMI\n",
    "        # Recommendation for Scenario 1\n",
    "        diet = 'Controlled carbohydrate intake with emphasis on complex carbs, fiber-rich foods, and portion control.'\n",
    "        exercise = 'Increased physical activity to aid in weight management and improve insulin sensitivity. Regular aerobic exercises like brisk walking, cycling, or swimming for at least 30 minutes a day. Incorporation of strength training exercises to build muscle mass and boost metabolism.'\n",
    "    elif glucose_level <= glucose_threshold and bmi <= bmi_threshold:\n",
    "        # Scenario 2: Within desirable ranges for blood glucose and BMI\n",
    "        # Recommendation for Scenario 2\n",
    "        diet = 'Maintain a balanced diet for continued health and weight management. Emphasis on a diverse range of nutrients from various food groups. Portion control and moderation in consuming high-calorie or processed foods. Focus on fruits, vegetables, whole grains, lean protein sources, and healthy fats.'\n",
    "        exercise = 'Sustained moderate physical activity for overall health maintenance. Regular moderate exercises such as walking, light jogging, or recreational sports for at least 30 minutes most days of the week. Engaging in activities that promote flexibility, balance, and cardiovascular health.'\n",
    "    else:\n",
    "        # Default recommendation if conditions don't match predefined thresholds\n",
    "        diet = 'Balanced diet'\n",
    "        exercise = 'Moderate exercise'\n",
    "\n",
    "    return diet, exercise\n",
    "\n",
    "# User input for individual's health metrics\n",
    "glucose_input = float(input(\"Enter the individual's glucose level: \"))\n",
    "bmi_input = float(input(\"Enter the individual's BMI: \"))\n",
    "# Get diet and exercise recommendations based on the user-inputted health metrics\n",
    "diet_recommendation, exercise_recommendation = get_diet_and_exercise(glucose_input, bmi_input)\n",
    "\n",
    "\n",
    "print('Dietary plan:', diet_recommendation)\n",
    "print()\n",
    "print('Exercise recommendations:', exercise_recommendation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
